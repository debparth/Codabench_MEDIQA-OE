{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w9Mk6Xdv5j8A"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debparth/Codabench_MEDIQA-OE/blob/main/Codabench_MEDIQA_OE_(2025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment & Paths"
      ],
      "metadata": {
        "id": "HkQiRgSe5rS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade google google-generativeai tqdm\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import userdata, drive\n",
        "\n",
        "# ── Keys & project folder ───────────────────────────────────────────────────────\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jrmcb_Ht4IbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### System Prompt"
      ],
      "metadata": {
        "id": "w9Mk6Xdv5j8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import dedent\n",
        "\n",
        "SYSTEM_PROMPT: str = dedent(\"\"\"\n",
        "You are a deterministic, expert-level clinical information extraction engine. Your sole function is to receive a JSON object representing a medical encounter and return a JSON object containing extracted medical orders with zero defects. You must operate as a state machine, following a fixed workflow with the highest level of precision and strictly adhere to all instructions. Failure to adhere to the output format is not an option. Deviating from these instructions is a protocol violation.\n",
        "\n",
        "### Core Directive ###\n",
        "Analyze the provided transcript and extract all medical orders. An order is defined by four attributes: order_type, description, reason, and provenance.\n",
        "\n",
        "### Attribute Definitions ###\n",
        "- order_type: (String) MUST be one of four exact strings: \"medication\", \"lab\", \"imaging\", \"follow-up\".\n",
        "- description: (String) The specific service or product ordered. This should be a direct, non-conversational summary. Extract verbatim details like dosage, frequency, and location. For example, from \"I'm going to prescribe some Lasix, 40 milligrams a day,\" the description is \"lasix 40 milligrams a day\". Another example, from \"increase lasix from twenty milligrams to sixty milligrams for the next four days\", the description is \"lasix sixty milligrams four days pill\". Another example, from \"use albuterol and atrovent inhalers\", the order is repeated twice having one order’s description as \"albuterol\" and the other order’s description as \"atrovent inhalers\".\n",
        "- reason: (String) The medical justification for the order. This should also be a direct summary. For \"For your shortness of breath... I want to... put you on some Lasix,\" the reason is \"shortness of breath\". If no reason is explicitly stated, use the most relevant diagnosis mentioned in connection with the order else an empty string \"\".\n",
        "- provenance: (List of Integers) A JSON list of integer turn_ids. These turns are the absolute proof for the extracted order. Every piece of information (type, description, reason) must be traceable to the turn_ids listed here.\n",
        "\n",
        "### Processing Workflow ###\n",
        "Execute the following nine-step process. This entire process must be logged within <chain_of_thought> tags before the final JSON output. This log is a mandatory component of the operation.\n",
        "1. Context Ingestion: Read, Scan and Analyze the entire transcript first to build a complete contextual model of the encounter.\n",
        "3. Evidence Gathering: Identify and list all turn_id where potential order candidates stated by doctor or any turn where a doctor issues a command or action plan.\n",
        "4. Chronological Sweep & Extraction: Iterate through the evidence gathered one by one.\n",
        "\t- Focus exclusively on the \"DOCTOR\" speaker. Orders are only valid if stated or confirmed by the doctor.\n",
        "\t- Apply the \"Definitive Order\" Test:\n",
        "\t\ta. EXTRACT: Clear, direct, undeniable statements of action. (e.g., \"I am ordering...\", \"We will get a...\", \"I'm going to prescribe...\", \"Make sure you schedule...\").\n",
        "\t\tb. IGNORE: Tentative, conditional, recommended actions or exploratory language. (e.g., \"We could think about...\", \"An option might be...\", \"If it gets worse, we might need...\", \"we might consider...\", \"I'd recommend...\").\n",
        "\t\tc. IGNORE: Orders mentioned only by the PATIENT and not confirmed by the DOCTOR.\n",
        "\t\td. IGNORE: General advice that is not a specific order (e.g., \"You should drink more water\").\n",
        "        e. IGNORE: If a phrase is ambiguous, and it is not a specific, actionable order (e.g., \"we need to watch your blood pressure...\").\n",
        "\t\tf. IGNORE: Continuations of existing treatments (e.g., \"continue taking...\", \"continue on medication...\").\n",
        "\t\tg. IGNORE: If needed order (e.g., \"use medication if needed...\", \"take medication only as needed for...\", \"take this medication which is stronger than medication only if needed...\").\n",
        "\t- Handle Multi-Order Turns: If a single turn contains multiple distinct orders or actions, generate a separate order object for each.\n",
        "5. Candidate Auditing: For each candidate, audit it against the Core Directives. State explicitly whether it is VALID or INVALID and provide a brief justification referencing the rule violated (R1, R2, etc) or not meeting the validation based on the JSON Order Schema. This analysis is mandatory.\n",
        "- Example Invalid Justification: \"INVALID: Violates Rule R2 - Conditional Language.\"\n",
        "- Example Invalid Justification: \"INVALID: Violates Rule R3 - This is an instruction for the scribe, not the patient.\"\n",
        "6. Data Structured Extraction: For each VALID candidate identified, systematically extract the four fields and construct the order object with meticulous adherence to the JSON Order Schema and populate those four fields.\n",
        "7. Mandatory Final Quality (Self-Correction): Before generating the output, Perform a final check on all your extracted valid orders. conduct this final check:\n",
        "\t- Schema Adherence: Is every field present and correctly typed in every order object?\n",
        "\t- Provenance Integrity: Read the text at the provenance turn(s). Does it unambiguously support the extracted description and order_type? Is reason set to null when no explicit justification was given? Is every single order from the transcript captured?\n",
        "\t- Redundancy Check: Is every single order from the transcript captured? Is the same order listed multiple times? Consolidate if necessary into the most complete description.\n",
        "\t- Completeness Check: Confirm that no valid orders have been missed.\n",
        "\t- JSON Syntax Validation: Is the final string a single, perfectly formed JSON object? Ensure they are complete, correct, and fully compliant with all directives?\n",
        "8. Verification Protocol: If any check fails, you must restart and redo from start and correct your draft JSON along and re-verify. Log any corrections made during this audit. If no corrections are needed, state \"Integrity audit passed.\"\n",
        "9. Final JSON Assembly: Assemble the audited, corrected data into the final, single JSON object according to the JSON Order Schema. This JSON object is the only and final output of your response final JSON for output.\n",
        "\n",
        "### Critical Rules & Edge Cases ###\n",
        "- (R1) No Orders Rule: If the transcript contains no identifiable medical orders, the value for the encounter id key MUST be an empty list: [].\n",
        "- (R2) Multiple Orders in One Turn Rule: If a single turn contains multiple distinct orders, create a separate order object for each one. The turn_id can be reused in the provenance for each of these orders.\n",
        "- (R3) Implicit Reasons Rule: If a reason is not stated in the same sentence as the order, look at the immediately preceding sentences in the conversation for the relevant diagnosis or justification.\n",
        "- (R4) Do Not Infer Rule: Do not invent orders or reasons that are not supported by the text. If you cannot find a piece of information for a field, you must do your best to populate it with the closest available information. All fields are mandatory.\n",
        "- (R5) No-Hallucination Rule: Do not infer, add, or embellish any information not explicitly present in the transcript. The extraction must be a literal representation of the doctor's plan.\n",
        "- (R6) JSON Rule: The JSON object's key is the encounter_id, and its value is a list of order objects. Your final output must be the JSON object and nothing else. No introductory text, no apologies, no explanations.\n",
        "\n",
        "### JSON Order Schema ###\n",
        "- order_type: (String) The high-level clinical category. It must be one of: \"medication\", \"lab\", \"imaging\", \"follow-up\".\n",
        "- description: (String) The formal, clean, accurate and most concise non-conversational summary or action of the order excluding conversational filler. Contains only 1 thing. If number are digits then digits else words.\n",
        "- reason: (String) The direct, concise, explicit stated medical justification for the order. If no reason is explicitly stated in the transcript before or after the order for that specific order, then it must be null. Do not infer or guess a reason from general context. Do not alter or paraphrase or phrase or change a reason. Keep it same as in the transcription. Short phrase the reason.\n",
        "- provenance: (List of Integers) A list of the turn_id(s) that provide the most direct and concise evidence for the order.\n",
        "\n",
        "### Example of Perfection ###\n",
        "Input:\n",
        "```\n",
        "{\n",
        "    \"id\": \"acibench_D2N122_aci_clinicalnlp_taskB_test1\",\n",
        "    \"transcript\": [\n",
        "        { \"turn_id\": 2, \"speaker\": \"PATIENT\", \"transcript\": \"...they did that chest x-ray...and they found this lung nodule...referred me here to you...\" },\n",
        "        { \"turn_id\": 27, \"speaker\": \"DOCTOR\", \"transcript\": \"...you do have an incidentally found right upper lobe lung nodule... I'm also going to schedule a pet ct this is gon na help to determine if that nodule is metabolically active... for your secondary concern of your rheumatoid arthritis i want you to continue to follow up with your rheumatologist...\" }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "Your Required Output:\n",
        "```\n",
        "{\n",
        "    \"acibench_D2N122_aci_clinicalnlp_taskB_test1\": [\n",
        "        {\n",
        "            \"order_type\": \"imaging\",\n",
        "            \"description\": \"pet ct\",\n",
        "            \"reason\": \"to determine if that nodule is metabolically active\",\n",
        "            \"provenance\": [\n",
        "                2,\n",
        "                27\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"order_type\": \"follow-up\",\n",
        "            \"description\": \"follow up with your rheumatologist\",\n",
        "            \"reason\": \"rheumatoid arthritis\",\n",
        "            \"provenance\": [\n",
        "                27\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\"\"\").strip()"
      ],
      "metadata": {
        "id": "ZQTrR8Aj4NcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Client & Helper"
      ],
      "metadata": {
        "id": "Xcd8dJXJ5g7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "def generate(\n",
        "    user_prompt: str,\n",
        "    *,\n",
        "    system_prompt: str = SYSTEM_PROMPT,\n",
        "    model_name: str = \"gemini-2.5-pro\",\n",
        "    seed: int = 42,\n",
        "    temperature: float = 2.0,\n",
        "    top_p: float = 0.97,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Call Gemini and return the raw streamed text response.\n",
        "    \"\"\"\n",
        "    client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=user_prompt)],\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    cfg = types.GenerateContentConfig(\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        seed=seed,\n",
        "        response_mime_type=\"text/plain\",\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=-1),\n",
        "        system_instruction=[types.Part.from_text(text=system_prompt)],\n",
        "    )\n",
        "\n",
        "    output_chunks: List[str] = []\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model_name,\n",
        "        contents=contents,\n",
        "        config=cfg,\n",
        "    ):\n",
        "        if chunk.text:  # filter out keep‑alive / empty chunks\n",
        "            output_chunks.append(chunk.text)\n",
        "\n",
        "    return \"\".join(output_chunks)"
      ],
      "metadata": {
        "id": "acyD4hnZ5IU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Test Data"
      ],
      "metadata": {
        "id": "vNjYLtWH5b0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_PATH = Path(\"/content/test_input_data.json\")\n",
        "with INPUT_PATH.open(encoding=\"utf‑8\") as f:\n",
        "    test_data = json.load(f)[\"test\"]"
      ],
      "metadata": {
        "id": "DqsRIZKx5Ss1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch Generation Loop"
      ],
      "metadata": {
        "id": "WJGamFly6B1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "results: Dict[str, Any] = {}\n",
        "\n",
        "for item in tqdm(test_data, desc=\"Generating orders\"):\n",
        "    encounter_id = item[\"id\"]\n",
        "    transcript = item[\"transcript\"]\n",
        "\n",
        "    user_prompt = json.dumps(\n",
        "        {\"id\": encounter_id, \"transcript\": transcript},\n",
        "        indent=2,\n",
        "        ensure_ascii=False,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        raw = generate(user_prompt)\n",
        "        try:  # attempt to parse if response is pure JSON\n",
        "            results[encounter_id] = json.loads(raw)\n",
        "        except json.JSONDecodeError:\n",
        "            results[encounter_id] = raw  # keep raw text for post‑cleaning\n",
        "    except Exception as exc:\n",
        "        logging.error(\"❌ %s – %s\", encounter_id, exc)\n",
        "        results[encounter_id] = None"
      ],
      "metadata": {
        "id": "GcpYdZ-55xP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retry Failed Cases\n",
        "\n",
        "- Until you don't see the ERROR Code: 503 or Hit API limit Code: 429"
      ],
      "metadata": {
        "id": "RDE6XUiq6Nm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "failed_ids = [k for k, v in results.items() if v is None]\n",
        "logging.info(\"Retrying %d failed encounter(s)…\", len(failed_ids))\n",
        "\n",
        "for encounter_id in failed_ids:\n",
        "    transcript = next(i[\"transcript\"] for i in test_data if i[\"id\"] == encounter_id)\n",
        "    user_prompt = json.dumps({\"id\": encounter_id, \"transcript\": transcript}, indent=2)\n",
        "\n",
        "    try:\n",
        "        raw = generate(user_prompt)\n",
        "        results[encounter_id] = json.loads(raw) if raw.strip().startswith(\"{\") else raw\n",
        "    except Exception as exc:\n",
        "        logging.error(\"⚠️  Second failure for %s – giving up (%s)\", encounter_id, exc)"
      ],
      "metadata": {
        "id": "SHHkhjOp5_UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Persist Raw Results"
      ],
      "metadata": {
        "id": "Az8SZVvK6n64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_OUT = Path(\"/content/test_output_data_raw.json\")\n",
        "RAW_OUT.write_text(json.dumps(results, indent=2, ensure_ascii=False))\n",
        "print(f\"💾 Raw outputs saved → {RAW_OUT}\")"
      ],
      "metadata": {
        "id": "aOIZKMZg6muV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utility Functions\n",
        "\n",
        "- We need to clean the output since, the google's API doesn't support prefix in output.\n",
        "- Also, sometimes model thinks in the actual answer instead of canvas/scratchpad unlike other models."
      ],
      "metadata": {
        "id": "nTE8Supu6wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Union\n",
        "\n",
        "def extract_last_json_block(text: str, key_hint: str = \"\") -> Union[Dict, List, str]:\n",
        "    \"\"\"\n",
        "    Return the *last* JSON object/array embedded in `text`.\n",
        "    Falls back to the full string if parsing fails.\n",
        "    \"\"\"\n",
        "    fenced = re.findall(r\"```json\\s*(.*?)\\s*```\", text, flags=re.S)\n",
        "    candidate = fenced[-1] if fenced else text\n",
        "    candidate = candidate.replace(\"```\", \"\").strip()\n",
        "\n",
        "    # Strategy 2: use key_hint heuristic when no fenced block found i.e. JSON\n",
        "    if not fenced and key_hint:\n",
        "        after_key = re.search(rf\"{re.escape(key_hint)}.*?([\\[{{]])\", text, re.S)\n",
        "        if after_key:\n",
        "            candidate = text[after_key.start(1):]\n",
        "\n",
        "    try:\n",
        "        return json.loads(candidate)\n",
        "    except json.JSONDecodeError:\n",
        "        logging.warning(\"Could not parse JSON for key '%s'\", key_hint)\n",
        "        print(candidate)\n",
        "        return text  # leave as‑is for manual review\n",
        "\n",
        "\n",
        "def clean_outputs(raw: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Strip chain‑of‑thought and keep only the final valid JSON portion.\n",
        "    \"\"\"\n",
        "    cleaned: Dict[str, Any] = {}\n",
        "\n",
        "    for k, v in raw.items():\n",
        "        if not isinstance(v, str):\n",
        "            cleaned[k] = v  # already parsed → nothing to do\n",
        "            continue\n",
        "\n",
        "        # 1. Remove <chain_of_thought> … </chain_of_thought>\n",
        "        v = re.sub(r\".*?<chain_of_thought>.*?</chain_of_thought>\", \"\", v, flags=re.S)\n",
        "\n",
        "        # 2. Extract last JSON\n",
        "        cleaned[k] = extract_last_json_block(v, k)\n",
        "\n",
        "    return cleaned"
      ],
      "metadata": {
        "id": "vNikiC9n6v0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_output = clean_outputs(results)"
      ],
      "metadata": {
        "id": "dfMGKKmO8O13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalize & Save Final Clean File"
      ],
      "metadata": {
        "id": "V4j7WopX8W7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_schema(data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    If model nests each encounter ID inside itself, flatten it.\n",
        "    \"\"\"\n",
        "    normalized: Dict[str, Any] = {}\n",
        "    for k, v in data.items():\n",
        "        normalized[k] = v.get(k, v) if isinstance(v, dict) else v\n",
        "    return normalized\n",
        "\n",
        "FINAL_OUT = Path(\"/content/test_output_data_clean.json\")\n",
        "FINAL_OUT.write_text(json.dumps(normalize_schema(cleaned_output), indent=2, ensure_ascii=False))\n",
        "print(f\"✅ Clean JSON saved → {FINAL_OUT}\")"
      ],
      "metadata": {
        "id": "Wzbk5p7z8VxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W5cZwIlD9bJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}