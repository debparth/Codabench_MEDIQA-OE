# ğŸ©º Medical-Order Extraction from Doctorâ€“Patient Dialogues  
*Solo-Task submission Â· 2áµˆ place on the public leaderboard*

> â€œReduce documentation burden, surface critical orders, and let clinicians focus on care.â€

---

## TL;DR

This notebook demonstrates an endâ€‘toâ€‘end pipeline for **medicalâ€‘order extraction** from doctorâ€“patient conversations.â€¯It ingests the *ACIâ€‘Bench* and *PriMock57* transcripts, applies advanced promptâ€‘engineering around **Geminiâ€¯2.5â€¯Pro** (You can use it on any closed source models like **Mistralâ€¯Mediumâ€¯3.2**, etc), postâ€‘processes and normalises the JSON output, and writes leaderboardâ€‘ready predictions. Earlier iterations using BioBERT, DeBERTaâ€‘v3, BioClinicalâ€‘ModernBERT, T5, MedGemmaâ€¯4B and Lingshu 7B informed the final design but were ultimately outperformed by a pureâ€‘LLM + chainâ€‘ofâ€‘thought + Self-Critique + Zero Shot strategy. All key stepsâ€”from data loading to cleaningâ€”are modular, reproducible, and GPUâ€‘free.

---

## 1â€¯â€¯|â€¯â€¯Project Background

### 1.1Â Task

Extract structured orders (â€¯`order_type`, `description`, `reason`, `provenance`â€¯) from lengthy conversational transcripts to lighten clinical documentation burden and preserve critical patient information. The shared task ranks submissions by **ROUGEâ€‘1 F1** on descriptions and reasons, plus strict F1 on orderâ€‘type and multiâ€‘label provenance.([ACL Anthology][1])
Leaderboard scoring averages four metrics: `description_Rouge1_f1`, `reason_Rouge1_f1`, `order_type_Strict_f1`, and `provenance_MultiLabel_f1`.

### 1.2Â Datasets

| Split  | Encounters | Orders | Sources                   |
| ------ | ---------: | -----: | ------------------------- |
| Train  |        Â 63 |    143 | *ACIâ€‘Bench*â€¯+â€¯*PriMock57* |
| DevÂ Â Â  |       Â 100 |    255 | same                      |

* **ACIâ€‘Bench**Â captures freeâ€‘flowing clinic visits without virtualâ€‘assistant cues.([PubMed Central][2])
* **PriMock57**Â contains 57 mock primaryâ€‘care consultations with gold transcripts and notes.([GitHub][3], [ACL Anthology][4])

---

## 2â€¯â€¯|â€¯â€¯Modelâ€‘Selection Journey

| Phase | Goal                    | Model(s)                                                                                           | Rationale                                | Outcome                                            |
| ----- | ----------------------- | -------------------------------------------------------------------------------------------------- | ---------------------------------------- | -------------------------------------------------- |
| Â â‘     | Â Classify orderâ€‘type    | **BioBERT**([arXiv][5])                                                                            | domainâ€‘specific encoder                  | weak recall                                        |
| Â â€¦    | NER for attributes      | **DeBERTaâ€‘v3**([Hugging Face][6])                                                                  | superior tokenâ€‘level F1                  | inconsistent spans                                 |
| Â â‘¡    | Joint classâ€‘&â€‘generate  | **BioClinicalâ€‘ModernBERT**([arXiv][7], [Hugging Face][8]) Â +Â  **T5**([arXiv][9])                   | longâ€‘context encoder + versatile decoder | better order separation but low narrative fidelity  |
| Â â‘¢    | Endâ€‘toâ€‘end generation   | **MedGemmaÂ 4B**([Google for Developers][10]), **Lingshu 7B**([arXiv][11])                            | SOTA medical LLMs                        | GPU OOM on Colab even with 4-bit quant                             |
| Â â‘£    | Promptâ€‘engineering only | **Geminiâ€¯2.5â€¯Pro**([Google DeepMind][12]), **Mistralâ€¯Mediumâ€¯3.2**([Mistral AI Documentation][13]) | zeroâ€‘server costs, strong reasoning      | **ğŸ¥ˆ 0.601 avg score with zero training** (â‰ˆâ€¯+13â€¯F1 over phaseÂ â‘¡)        |

> **Key insight:** a carefully crafted *CoTâ€¯â†’â€¯selfâ€‘verify â†’ finalâ€‘JSON* prompt with a deterministic seed delivered more gains than custom fineâ€‘tuning under tight compute budgets.

---

## 3â€¯â€¯|â€¯â€¯Notebook Overview

| Cell                 | Purpose                                               |
| -------------------- | ----------------------------------------------------- |
| Â 1Â Â Environment      | Mount Drive, set paths, install `google-generativeai` |
| Â 2Â Â System prompt    | Immutable stateâ€‘machine instruction                   |
| Â 3Â Â `generate()`     | Typed, loggingâ€‘aware wrapper around Gemini API        |
| Â 4Â Â Data load        | Read `test_input_data.json`                           |
| Â 5Â Â Batch run        | Stream results with progress bar & robust parsing     |
| Â 6Â Â Retry logic      | Oneâ€‘pass recovery of failed IDs                       |
| Â 7Â Â Persist raw      | `test_output_data_raw.json`                           |
| Â 8Â Â Utils            | Extract last valid JSON block, remove CoT, parse JSON |
| Â 9  Normalise & save | Flatten keys, produce `test_output_data_clean.json`   |

---

## 4â€¯â€¯|â€¯â€¯Getting Started

```bash
# clone and open in Colab
!git clone https://github.com/yourâ€‘org/medâ€‘orderâ€‘extractor
```

1. **Set the `GOOGLE_API_KEY`** in Colabâ€™s *User Settingsâ€¯â–¸â€¯Secrets*.
2. Run the notebook topâ€‘toâ€‘bottom (GPU **not** required).
3. Submit the zipped `test_output_data_clean.json` as `pred_orders.json`.

---

## 5â€¯â€¯|â€¯â€¯LeaderBoard Results

| Rank | description<br>Rouge-F1 | reason<br>Rouge-F1 | order_type<br>Strict-F1 | provenance<br>ML-F1 | **Avg** |
|------|------------------------:|-------------------:|------------------------:|--------------------:|---------|
| #1 (SOTA) | **0.6677** | 0.2949 | **0.8145** | **0.6304** | **0.6019** |
| **#2 (Ours)** | 0.6406 | **0.4130** | 0.7474 | 0.6044 | **0.6014** |
| #3 | 0.5799 | 0.3564 | 0.7156 | 0.4838 | 0.5339 |

---

## 6â€¯â€¯|â€¯â€¯Cite & Acknowledge

* Leeâ€¯etâ€¯al., â€œBioBERT: a preâ€‘trained biomedical language modelâ€ (2019)([arXiv][5])
* Heâ€¯etâ€¯al., â€œDeBERTaâ€¯v3: Improving DeBERTa using ELECTRAâ€‘style preâ€‘trainingâ€ (2021)([Hugging Face][6])
* Sounackâ€¯etâ€¯al., â€œBioClinical ModernBERTâ€ (2025)([arXiv][7])
* Raffelâ€¯etâ€¯al., â€œExploring the Limits of Transfer Learning with a Unified Textâ€‘toâ€‘Text Transformerâ€ (T5)([arXiv][9])
* GoogleÂ HealthÂ AI, â€œMedGemmaÂ 4â€¯B Model Cardâ€ (2025)([Google for Developers][10])
* Xiaoâ€¯etâ€¯al., â€œLingshu: A Generalist Foundation Model for Unified Multimodal Medicineâ€ (2025)([arXiv][11])
* DeepMind, â€œGeminiÂ 2.5â€¯Proâ€ (2025)([Google DeepMind][12])
* Mistralâ€¯AI, â€œModels Overviewâ€ (2025)([Mistral AI Documentation][13])
* Korfiatisâ€¯etâ€¯al., â€œPriMock57 Datasetâ€ (2022)([ACL Anthology][4])
* Ouyangâ€¯etâ€¯al., â€œACIâ€‘Bench: Ambient Clinical Intelligence Datasetâ€ (2023)([PubMed Central][2])

---

### Happy extracting! ğŸ¯

[1]: https://aclanthology.org/2021.bionlp-1.8/ "Overview of the MEDIQA 2021 Shared Task on Summarization in ..."
[2]: https://pmc.ncbi.nlm.nih.gov/articles/PMC10482860/ "Aci-bench: a Novel Ambient Clinical Intelligence Dataset for ..."
[3]: https://github.com/babylonhealth/primock57 "babylonhealth/primock57: Dataset of 57 mock medical ... - GitHub"
[4]: https://aclanthology.org/2022.acl-short.65/ "PriMock57: A Dataset Of Primary Care Mock Consultations"
[5]: https://arxiv.org/abs/1901.08746 "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
[6]: https://huggingface.co/microsoft/deberta-v3-base "microsoft/deberta-v3-base - Hugging Face"
[7]: https://arxiv.org/abs/2506.10896 "BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP"
[8]: https://huggingface.co/collections/thomas-sounack/bioclinical-modernbert-681b824d12b9b6899841f8c7 "BioClinical ModernBERT - a thomas-sounack Collection"
[9]: https://arxiv.org/abs/1910.10683 "Exploring the Limits of Transfer Learning with a Unified Text-to-Text ..."
[10]: https://developers.google.com/health-ai-developer-foundations/medgemma/model-card "MedGemma model card | Health AI Developer Foundations"
[11]: https://arxiv.org/html/2506.07044v1 "Lingshu: A Generalist Foundation Model for Unified Multimodal ..."
[12]: https://deepmind.google/models/gemini/pro/ "Gemini 2.5 Pro - Google DeepMind"
[13]: https://docs.mistral.ai/getting-started/models/models_overview/ "Models Overview - Mistral AI Documentation"
